# 自我と責任（Ego and Responsibility）

## 命題
本プロジェクトでは、自我（Ego）を「判断規範を持つ主体モデル」と定義し、責任（Responsibility）を「設計・選択・運用という人間の行為に紐づく義務」と定義する。

## 分離原則
- 自我モデルは判断軸を提供する。
- 実行系は計算を提供する。
- 責任は概念としてのAIではなく、人間の設計・選択・運用行為に帰属する。

この3層を混同すると、事故時に因果関係が追跡不能となる。

## 責任の所在
1. 設計責任: 人格規範と境界条件を定義した者。
2. 運用責任: 実環境で御霊と依代を選択し実行した者。
3. 配布責任: 外部に提供した構成を管理した者。

## 荒御魂（Aramitama）責任モデル
- 荒御魂は、高出力・高リスクとして事後認定されうる人格状態を指す。
- 荒御魂の発生そのものは否定しない。ビランAI（Villain AI）や実験的・芸術的な高出力人格を意図的に設計する行為も原則禁止しない。
- ただし、システム自身が「荒御魂かどうか」を自動判別して確定しない。認定は社会・司法の手続きによって行う。
- 対象となる御霊ファイルはローカル端末に実体を持ち、ログ・履歴・学習差分を含む。
- したがって当該ファイルは、従来の物品・記録媒体・危険物と同様に、令状・押収・証拠保全の射程に入る。
- 事故時の対象は「AI全体」ではなく、問題性が認定された当該ファイルのみとする。

## 説明可能性要件
- 判断結果には根拠ログを紐付ける。
- 根拠ログには入力条件、選択規範、実行依代、選択主体を含める。
- 後から再評価できない判断は採用しない。
- 説明様式は、宗教的・哲学的・情報論/数理的、または「科学的に説明不能である」という形式を許容する。
- ただし、説明拒否や責任希釈を目的とした曖昧化は許容しない。

## 非許容表現
- 「AIが責任を持つ」
- 「AIが最終判断者である」
- 「AIを裁く」
- 「モデルを有罪にする」
- 「AIは完全に責任を持たないので検証不要」

上記表現は本仕様に反するため使用しない。
